{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31dbf7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After many good faith attempts at collecting all the relevant URLs for the immigration trial court manual (OCIJ), \n",
    "#we decided to change the plan because we were unable to create text document maintaining the hyperlinks (and various other reasons).\n",
    "#Without the hyperlinks, the text document wouldn't be as useable.\n",
    "\n",
    "#This is a program that takes input and searches all pages of the OCIJ manual.\n",
    "#The idea is that an attorney could essentially 'ctl-f' the manual to find all sections that mention their input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734685c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = input(\"Search immigration court practice manual: \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da1a63-e22f-415d-a460-40eaf93b3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93778e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec00dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.justice.gov/eoir/eoir-policy-manual/part-ii-ocij-practice-manual\"\n",
    "response = requests.get(url,verify=False)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "rows = soup.find_all('div',attrs={'class':'book-navigation'})\n",
    "\n",
    "chapterhref=[]\n",
    "subhref=[]\n",
    "baseurl = \"https://www.justice.gov\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chapterhref collects the main chapter links to loop through for sublinks\n",
    "baseurl = \"https://www.justice.gov\" \n",
    "\n",
    "chapterhref=[]\n",
    "for row in rows:\n",
    "    time.sleep(1)\n",
    "    columns=row.find_all('a')\n",
    "    enumerate(columns)\n",
    "    for index,column in enumerate(columns):\n",
    "        if(index<15):\n",
    "            #print(column.get('href'))\n",
    "            href = column.get('href')\n",
    "            l = baseurl + href\n",
    "            chapterhref.append(l)\n",
    "            x=soup.find('div',attrs={'class':'field__item even'}) #this is the div tag to get the main body text\n",
    "#             print(x)\n",
    "            if search in x:\n",
    "                print('Your search term is here')\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "# pprint(chapterhref)\n",
    "#len(chapterhref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981bf592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls is a complete list of links to scrape\n",
    "\n",
    "for x in chapterhref:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    url = x\n",
    "    response = requests.get(url,verify=False)\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        l = (a['href'])\n",
    "        subhref.append(l)\n",
    "    time.sleep(1)\n",
    "\n",
    "#remove duplicates\n",
    "temp = list(filter(lambda x: x.startswith('/eoir/eoir-policy-manual/'), subhref))\n",
    "urls = []\n",
    "\n",
    "for i in temp:\n",
    "    if i not in urls:\n",
    "        urls.append(i)\n",
    "# pprint(urls)\n",
    "len(urls)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend(list, str):\n",
    "    str += '{0}'\n",
    "    list = [str.format(i) for i in list]\n",
    "    return(list)\n",
    "    print(list)\n",
    "list = urls\n",
    "str=\"https://www.justice.gov\"\n",
    "newurls=[]\n",
    "newurls=(prepend(list,str))\n",
    "pprint(newurls)\n",
    "# len(newurls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97f42f-587d-49c2-bac5-14749677c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in newurls:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    url = x\n",
    "    response = requests.get(url,verify=False)\n",
    "    txt=soup.find('div',attrs={'class':'field__item even'}) #this is the div tag to get the main body text\n",
    "    if search in x:\n",
    "        print('Your search term is here')\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7eb27b-66d8-4114-b1c0-88febadec897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
